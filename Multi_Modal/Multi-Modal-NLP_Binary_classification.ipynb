{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiModalPredictor - is a deep learning \"model zoo\" of model zoos. It can automatically build deep learning models that are suitable for multimodal datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind, the tabular predictor does use some neural networks, but not to the degree of multimodal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5171"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TabularDataset(\"data/sentiment/spam_ham_dataset.csv\")\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...\n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
       "3  spam  Subject: photoshop , windows , office . cheap ...\n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3672\n",
       "spam    1499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\n",
      "Subject: re : indian springs\n",
      "this deal is to book the teco pvr revenue . it is my understanding that teco\n",
      "just sends us a check , i haven ' t received an answer as to whether there is a\n",
      "predermined price associated with this deal or if teco just lets us know what\n",
      "we are giving . i can continue to chase this deal down if you need .\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[4]['label'])\n",
    "print(data.iloc[4]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "Subject: photoshop , windows , office . cheap . main trending\n",
      "abasements darer prudently fortuitous undergone\n",
      "lighthearted charm orinoco taster\n",
      "railroad affluent pornographic cuvier\n",
      "irvin parkhouse blameworthy chlorophyll\n",
      "robed diagrammatic fogarty clears bayda\n",
      "inconveniencing managing represented smartness hashish\n",
      "academies shareholders unload badness\n",
      "danielson pure caffein\n",
      "spaniard chargeable levin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[3]['label'])\n",
    "print(data.iloc[3]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train and Test\n",
    "\n",
    "train_size = int(len(data)*0.8)\n",
    "seed = 42\n",
    "\n",
    "train_data = data.sample(train_size, random_state=seed)\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = MultiModalPredictor(label=\"label\",\n",
    "                                path=\"MM_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "AutoMM starts to create your model. ✨\n",
      "\n",
      "- Model will be saved to \"c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\01_multi_modal\\MM_model\".\n",
      "\n",
      "- Validation metric is \"roc_auc\".\n",
      "\n",
      "- To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\01_multi_modal\\MM_model\n",
      "    ```\n",
      "\n",
      "Enjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8783a68b203444569f044cf75137d6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\manor\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce27f9bf4db42d882f6b99e5972f496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01670b7ed92426585e504dc600fce22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503500d7b19944f6837f1c5c9c29d965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c878e7c449f642ac89cdfb6479eec29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\multimodal\\utils\\environment.py:93: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name              | Type                         | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | model             | HFAutoModelForTextPrediction | 108 M \n",
      "1 | validation_metric | AUROC                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss             | 0     \n",
      "-------------------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "435.573   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b070a0118a944f19be568f5a7f8a0f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e55bf8e5144d0d8504e8acfb5ddeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_roc_auc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictor\u001b[39m.\u001b[39;49mfit(train_data)\n",
      "File \u001b[1;32mc:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\multimodal\\predictor.py:825\u001b[0m, in \u001b[0;36mMultiModalPredictor.fit\u001b[1;34m(self, train_data, presets, config, tuning_data, max_num_tuning_data, id_mappings, time_limit, save_path, hyperparameters, column_types, holdout_frac, teacher_predictor, seed, standalone, hyperparameter_tune_kwargs, clean_ckpts)\u001b[0m\n\u001b[0;32m    818\u001b[0m     predictor \u001b[39m=\u001b[39m hyperparameter_tune(\n\u001b[0;32m    819\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m    820\u001b[0m         resources\u001b[39m=\u001b[39mresources,\n\u001b[0;32m    821\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_fit_args,\n\u001b[0;32m    822\u001b[0m     )\n\u001b[0;32m    823\u001b[0m     \u001b[39mreturn\u001b[39;00m predictor\n\u001b[1;32m--> 825\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_fit_args)\n\u001b[0;32m    826\u001b[0m training_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_train_time \u001b[39m=\u001b[39m training_end \u001b[39m-\u001b[39m training_start\n",
      "File \u001b[1;32mc:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\multimodal\\predictor.py:1409\u001b[0m, in \u001b[0;36mMultiModalPredictor._fit\u001b[1;34m(self, train_df, val_df, validation_metric_name, minmax_mode, max_time, save_path, ckpt_path, resume, enable_progress_bar, presets, config, hyperparameters, teacher_predictor, hpo_mode, standalone, clean_ckpts, **hpo_kwargs)\u001b[0m\n\u001b[0;32m   1394\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m hpo_mode:\n\u001b[0;32m   1395\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_top_k_average(\n\u001b[0;32m   1396\u001b[0m             model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   1397\u001b[0m             save_path\u001b[39m=\u001b[39msave_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1407\u001b[0m             clean_ckpts\u001b[39m=\u001b[39mclean_ckpts,\n\u001b[0;32m   1408\u001b[0m         )\n\u001b[1;32m-> 1409\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_best_score \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mcallback_metrics[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mval_\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validation_metric_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mitem()\n\u001b[0;32m   1410\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1411\u001b[0m     sys\u001b[39m.\u001b[39mexit(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining finished, exit the process with global_rank=\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mglobal_rank\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_roc_auc'"
     ]
    }
   ],
   "source": [
    "predictor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.1.3 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.1.3 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "Load pretrained checkpoint: c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\01_multi_modal\\email_ham_spam\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Loading a pretrained model\n",
    "predictor = MultiModalPredictor.load(\"email_ham_spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e49c0ceb8145d9b93ce8f400c207ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score on the holdout test dataset?\n",
    "test_score = predictor.evaluate(test_data, metrics=[\"acc\",\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9642512077294686, 'f1': 0.9384359400998336}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_spam = \"Subject: Free money\\n I am from Nigeria, I am a prince,give me your social security for free money!\"\n",
    "email_ham = \"Subject: Meeting on Tuesday\\n Wanted to check if you are still free on Tuesday?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\multimodal\\utils\\data.py:511: UserWarning: Replacing detected dataframe columns `['email']` with columns `['text']` from training data.Double check the correspondences between them to avoid unexpected behaviors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict({\"email\":[email_spam, email_ham]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\multimodal\\utils\\data.py:511: UserWarning: Replacing detected dataframe columns `['email']` with columns `['text']` from training data.Double check the correspondences between them to avoid unexpected behaviors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.2781119e-01, 8.7218881e-01],\n",
       "       [9.9959511e-01, 4.0496243e-04]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for prediction probabilities\n",
    "predictor.predict_proba({\"email\":[email_spam, email_ham]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.class_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
