{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  rating                                         reviewText  \\\n",
       "0  B0033UV8HI       3  Jace Rankin may be short, but he's nothing to ...   \n",
       "1  B002HJV4DE       5  Great short read.  I didn't want to put it dow...   \n",
       "2  B002ZG96I4       3  I'll start by saying this is the first of four...   \n",
       "3  B002QHWOEU       3  Aggie is Angela Lansbury who carries pocketboo...   \n",
       "4  B001A06VJ8       4  I did not expect this type of book to be in li...   \n",
       "\n",
       "       reviewerID  reviewerName  \n",
       "0  A3HHXRELK8BHQG        Ridley  \n",
       "1  A2RGNZ0TRF578I  Holly Butler  \n",
       "2  A3S0H2HV6U1I7F       Merissa  \n",
       "3   AC4OQW3GZ919J    Cleargrace  \n",
       "4  A3C9V987IQHOQD      Rjostler  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TabularDataset(\"data/kindle_review/review.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin             0\n",
       "rating           0\n",
       "reviewText       0\n",
       "reviewerID       0\n",
       "reviewerName    38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jace Rankin may be short, but he\\'s nothing to mess with, as the man who was just hauled out of the saloon by the undertaker knows now. He\\'s a famous bounty hunter in Oregon in the 1890s who, when he shot the man in the saloon, just finished a years long quest to avenge his sister\\'s murder and is now trying to figure out what to do next. When the snotty-nosed farm boy he just rescued from a gang of bullies offers him money to kill a man who forced him off his ranch, he reluctantly agrees to bring the man to justice, but not to kill him outright. But, first he needs to tell his sister\\'s widower the news.Kyla \"Kyle\" Springer Bailey has been riding the trails and sleeping on the ground for the past month while trying to find Jace. She wants revenge on the man who killed her husband and took her ranch, amongst other crimes, and she\\'s not so keen on the detour Jace wants to take. But she realizes she\\'s out of options, so she hides behind her boy persona as best she can and tries to keep pace. When a confrontation along the way gets her shot and Jace discovers that Kyle\\'s a Kyla, she has to come clean about the *whole* reason she needs this scoundrel dead and hope he\\'ll still help her.The book has its share of touching moments and slow-blooming romance. Kyla, we find out, has good reason to fear men and hide behind a boy\\'s persona. Watching Jace slowly pull her out of that shell and help her conquer her fears was endearing. Her pain was real and deeply-rooted and didn\\'t just disappear in the face of his sexiness. Neither did his understandable aversion to marriage magically disappear after a round of nookie. Why would a man who\\'s drifted from town to town for his entire adult life - a man who\\'s killed his fair share of men along the way - feel he\\'d make a good husband or father? They\\'re both the walking wounded and in a unique position to help each other, they just need time to realize it.However, while it was packed to bursting with my favorite themes - Old West setting, a heroine passing as male, a morally ambiguous hero, wounded souls, road romance, the kitchen sink - there was a certain...distance in the writing that kept me from getting carried away. Both characters were distinct and fully-formed and I couldn\\'t point to any glaring instances of bland telling or anything, I just never felt really invested. I enjoyed it quite a bit, as it was an exciting trip, but I was watching them from far away. I definitely wasn\\'t on the run alongside them. Add on a hasty and too tidy ending, and the book left me feeling a bit less than completely satisfied.I enjoyed the book, but I can\\'t say it was above average. I\\'d still read another book by the author.Note: I read the re-released ebook version and noticed there were a lot of formatting errors and missing words. I had to mentally edit as I read for some sentences to make sense. It wasn\\'t too too bad, but it was a little distracting.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reviewText'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size is: 9600\n"
     ]
    }
   ],
   "source": [
    "# Split of train test using sample\n",
    "train_size = int(len(data)*0.8)\n",
    "print(f\"Training size is: {train_size}\")\n",
    "\n",
    "seed = 42\n",
    "\n",
    "train_data = data.sample(train_size, random_state=seed)\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"first_mm_model\"\n",
    "\n",
    "predictor = TabularPredictor(label=\"rating\",\n",
    "                             path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"first_mm_model\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22000\n",
      "Train Data Rows:    9600\n",
      "Train Data Columns: 4\n",
      "Label Column: rating\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t5 unique label values:  [3, 1, 2, 4, 5]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12388.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.62 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tFitting RenameFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['reviewText']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 6657\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', [])       : 3 | ['asin', 'reviewerID', 'reviewerName']\n",
      "\t\t('object', ['text']) : 1 | ['reviewText']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    3 | ['asin', 'reviewerID', 'reviewerName']\n",
      "\t\t('int', ['binned', 'text_special']) :   32 | ['reviewText.char_count', 'reviewText.word_count', 'reviewText.capital_ratio', 'reviewText.lower_ratio', 'reviewText.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 6658 | ['__nlp__.000', '__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.14', ...]\n",
      "\t\t('object', ['text'])                :    1 | ['reviewText_raw_text']\n",
      "\t19.6s = Fit runtime\n",
      "\t4 features in original data used to generate 6694 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 134.81 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 21.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8640, Val Rows: 960\n",
      "Fitting 8 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.5344\t = Validation score   (accuracy)\n",
      "\t50.36s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.5427\t = Validation score   (accuracy)\n",
      "\t52.35s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tMany features detected (6693), dynamically setting 'colsample_bylevel' to 0.14940983116689077 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.6073\t = Validation score   (accuracy)\n",
      "\t346.47s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.5385\t = Validation score   (accuracy)\n",
      "\t132.11s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.3562\t = Validation score   (accuracy)\n",
      "\t16.87s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: VowpalWabbit ...\n",
      "\tWarning: Exception caused VowpalWabbit to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.5\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.5521\t = Validation score   (accuracy)\n",
      "\t175.77s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: MultiModalPredictor ...\n",
      "\tWarning: Exception caused MultiModalPredictor to fail during training... Skipping this model.\n",
      "\t\tThe total system num_gpus=0 is less than minimum num_gpus=1 to fit MultiModalPredictorModel. Consider using a machine with more GPUs.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1502, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1447, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 695, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 597, in _preprocess_fit_resources\n",
      "    assert system_num_gpus >= minimum_model_num_gpus, f'The total system num_gpus={system_num_gpus} is less than minimum num_gpus={minimum_model_num_gpus} to fit {self.__class__.__name__}. Consider using a machine with more GPUs.'\n",
      "AssertionError: The total system num_gpus=0 is less than minimum num_gpus=1 to fit MultiModalPredictorModel. Consider using a machine with more GPUs.\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6188\t = Validation score   (accuracy)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 816.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"first_mm_model\\\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x22c23c9cd60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(train_data, \n",
    "              hyperparameters=\"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If model generation takes long we can also load prebuilt from directory\n",
    "# predictor.TabularPredictor.load(\"book_rating\")\n",
    "# predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.618750       0.680925  548.067513                0.001089           0.268682            2       True          7\n",
      "1             CatBoost   0.607292       0.220986  346.473003                0.220986         346.473003            1       True          3\n",
      "2        LightGBMLarge   0.552083       0.479332  175.768492                0.479332         175.768492            1       True          6\n",
      "3           LightGBMXT   0.542708       0.326854   52.345429                0.326854          52.345429            1       True          2\n",
      "4              XGBoost   0.538542       0.108001  132.109430                0.108001         132.109430            1       True          4\n",
      "5             LightGBM   0.534375       0.303980   50.364038                0.303980          50.364038            1       True          1\n",
      "6       NeuralNetTorch   0.356250       0.023995   16.870968                0.023995          16.870968            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'LGBModel', 'XGBoostModel', 'CatBoostModel', 'WeightedEnsembleModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :    3 | ['asin', 'reviewerID', 'reviewerName']\n",
      "('int', ['binned', 'text_special']) :   32 | ['reviewText.char_count', 'reviewText.word_count', 'reviewText.capital_ratio', 'reviewText.lower_ratio', 'reviewText.digit_ratio', ...]\n",
      "('int', ['text_ngram'])             : 6658 | ['__nlp__.000', '__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.14', ...]\n",
      "('object', ['text'])                :    1 | ['reviewText_raw_text']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manor\\Downloads\\Automated Machine Learning with AutoGluon Library in Python\\autogluon_venv\\lib\\site-packages\\autogluon\\core\\utils\\plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBM': 'LGBModel',\n",
       "  'LightGBMXT': 'LGBModel',\n",
       "  'CatBoost': 'CatBoostModel',\n",
       "  'XGBoost': 'XGBoostModel',\n",
       "  'NeuralNetTorch': 'TabularNeuralNetTorchModel',\n",
       "  'LightGBMLarge': 'LGBModel',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBM': 0.534375,\n",
       "  'LightGBMXT': 0.5427083333333333,\n",
       "  'CatBoost': 0.6072916666666667,\n",
       "  'XGBoost': 0.5385416666666667,\n",
       "  'NeuralNetTorch': 0.35625,\n",
       "  'LightGBMLarge': 0.5520833333333334,\n",
       "  'WeightedEnsemble_L2': 0.61875},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'LightGBM': 'first_mm_model\\\\models\\\\LightGBM\\\\',\n",
       "  'LightGBMXT': 'first_mm_model\\\\models\\\\LightGBMXT\\\\',\n",
       "  'CatBoost': 'first_mm_model\\\\models\\\\CatBoost\\\\',\n",
       "  'XGBoost': 'first_mm_model\\\\models\\\\XGBoost\\\\',\n",
       "  'NeuralNetTorch': 'first_mm_model\\\\models\\\\NeuralNetTorch\\\\',\n",
       "  'LightGBMLarge': 'first_mm_model\\\\models\\\\LightGBMLarge\\\\',\n",
       "  'WeightedEnsemble_L2': 'first_mm_model\\\\models\\\\WeightedEnsemble_L2\\\\'},\n",
       " 'model_fit_times': {'LightGBM': 50.36403751373291,\n",
       "  'LightGBMXT': 52.34542918205261,\n",
       "  'CatBoost': 346.4730033874512,\n",
       "  'XGBoost': 132.10943031311035,\n",
       "  'NeuralNetTorch': 16.870967864990234,\n",
       "  'LightGBMLarge': 175.7684919834137,\n",
       "  'WeightedEnsemble_L2': 0.26868200302124023},\n",
       " 'model_pred_times': {'LightGBM': 0.30398035049438477,\n",
       "  'LightGBMXT': 0.32685351371765137,\n",
       "  'CatBoost': 0.22098636627197266,\n",
       "  'XGBoost': 0.1080009937286377,\n",
       "  'NeuralNetTorch': 0.02399468421936035,\n",
       "  'LightGBMLarge': 0.47933244705200195,\n",
       "  'WeightedEnsemble_L2': 0.0010890960693359375},\n",
       " 'num_bag_folds': 0,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 5,\n",
       " 'model_hyperparams': {'LightGBM': {'learning_rate': 0.05},\n",
       "  'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True},\n",
       "  'CatBoost': {'iterations': 10000,\n",
       "   'learning_rate': 0.05,\n",
       "   'random_seed': 0,\n",
       "   'allow_writing_files': False,\n",
       "   'eval_metric': 'Accuracy'},\n",
       "  'XGBoost': {'n_estimators': 10000,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_jobs': -1,\n",
       "   'proc.max_category_levels': 100,\n",
       "   'objective': 'multi:softprob',\n",
       "   'booster': 'gbtree',\n",
       "   'num_class': 5},\n",
       "  'NeuralNetTorch': {'num_epochs': 500,\n",
       "   'epochs_wo_improve': 20,\n",
       "   'activation': 'relu',\n",
       "   'embedding_size_factor': 1.0,\n",
       "   'embed_exponent': 0.56,\n",
       "   'max_embedding_dim': 100,\n",
       "   'y_range': None,\n",
       "   'y_range_extend': 0.05,\n",
       "   'dropout_prob': 0.1,\n",
       "   'optimizer': 'adam',\n",
       "   'learning_rate': 0.0003,\n",
       "   'weight_decay': 1e-06,\n",
       "   'proc.embed_min_categories': 4,\n",
       "   'proc.impute_strategy': 'median',\n",
       "   'proc.max_category_levels': 100,\n",
       "   'proc.skew_threshold': 0.99,\n",
       "   'use_ngram_features': False,\n",
       "   'num_layers': 4,\n",
       "   'hidden_size': 128,\n",
       "   'max_batch_size': 512,\n",
       "   'use_batchnorm': False,\n",
       "   'loss_function': 'auto'},\n",
       "  'LightGBMLarge': {'learning_rate': 0.03,\n",
       "   'num_leaves': 128,\n",
       "   'feature_fraction': 0.9,\n",
       "   'min_data_in_leaf': 3},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                  model  score_val  pred_time_val    fit_time  \\\n",
       " 0  WeightedEnsemble_L2   0.618750       0.680925  548.067513   \n",
       " 1             CatBoost   0.607292       0.220986  346.473003   \n",
       " 2        LightGBMLarge   0.552083       0.479332  175.768492   \n",
       " 3           LightGBMXT   0.542708       0.326854   52.345429   \n",
       " 4              XGBoost   0.538542       0.108001  132.109430   \n",
       " 5             LightGBM   0.534375       0.303980   50.364038   \n",
       " 6       NeuralNetTorch   0.356250       0.023995   16.870968   \n",
       " \n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                0.001089           0.268682            2       True   \n",
       " 1                0.220986         346.473003            1       True   \n",
       " 2                0.479332         175.768492            1       True   \n",
       " 3                0.326854          52.345429            1       True   \n",
       " 4                0.108001         132.109430            1       True   \n",
       " 5                0.303980          50.364038            1       True   \n",
       " 6                0.023995          16.870968            1       True   \n",
       " \n",
       "    fit_order  \n",
       " 0          7  \n",
       " 1          3  \n",
       " 2          6  \n",
       " 3          2  \n",
       " 4          4  \n",
       " 5          1  \n",
       " 6          5  }"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data[\"rating\"]\n",
    "test_features = test_data.drop(columns=[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        5\n",
       "4        5\n",
       "5        5\n",
       "9        4\n",
       "11       4\n",
       "        ..\n",
       "11980    1\n",
       "11981    5\n",
       "11983    4\n",
       "11986    5\n",
       "11997    2\n",
       "Name: rating, Length: 2400, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = predictor.predict(test_features)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.5845833333333333\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.5845833333333333,\n",
      "    \"balanced_accuracy\": 0.5644166663419024,\n",
      "    \"mcc\": 0.4739617862657992\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "metrics = predictor.evaluate_predictions(y_true=y_test,\n",
    "                                         y_pred=y_preds,\n",
    "                                         auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260  92  21  17  18]\n",
      " [116 176  44  32  14]\n",
      " [ 24  60 150 148  42]\n",
      " [  8  12  55 332 165]\n",
      " [  2   1   6 120 485]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
